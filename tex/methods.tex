%Incorporate priors on recent stock status based on Fisheries Management Index (FMI) scores and swept-area ratio data. This will allow the Value-of-Infomation (VoI, MÃ¤ntyniemi, et al., 2009) to be evaluated with respect to which data and expert knowledge are required to provide robust estimates for data-poor stocks.

Rather than using a data poor package with a set of often poorly documented assumptions we used the JABBA biomass dynamic model \citep{winker2018jabba} as it presents a unifying, flexible framework, based on a production function that can be used to estimate stock status and reference points under a variety of assumptions. JABBA is also used to conduct stock assessments for data moderate and rich stocks and so allows the value of improving data and knowledge to be evaluated.  


A Pella Tomlinson production function \citep{pella1969generalized} was assumed as this allows the shape of the production function to be varied, to represent alternative assumptions about productivity, stock status and reference points to be evaluated. At the data limited end of the stock assessment spectrum JABBA can be set up to approximate the behaviour of CMSY\cite{froese2017estimating}, sampling from prior distributions to obtain parameter values that given a catch history that does not crash the population and satisfy priors for initial and final depletion. At the data rich end JABBA can be fitted to an index of relative abundance or catch-per-unit-effort data with priors for the production function, i.e. population growth rate ($r$) and virgin biomass ($K$), and initial and final depletion. All modelling was performed in R using the FLR simulation framework \citep{kell2007flr}.

%Table \ref{tab:grid} summarises the alternative stock assessment assumptions made when running JABBA as a catch only method (COM). 

Two scenarios were considered for shape and $r$, since the shape of the production function is difficult to estimate from data alone even in data-rich assessments as it is determined by the form of density dependence assumed and parameters such as natural mortality ($M$) and the steepness of the stock-recruitment relationship ($h$) are difficult to estimate. Therefore the shape of the production function was assumed to be either logistic (Schaeffer) or Gompertz (Fox). In the latter case, production is maintained at the lower stock size, i.e. $B_{MSY}$ is found at a smaller fraction of virgin biomass $K$ than the former. The population growth rate at low stock size ($r$) can be derived from life-history parameters, however, it depends on the assumed values of $M$ and $h$. In many studies when developing uncertainty grids $M$ and $h$ are varied independently,  however, $h$ and $M$ are related as $h$ describes density dependent mortality of recruits. Therefore we set up two scenarios when estimating $r$, based on low or high $M$ and $h$.

To provide priors for the other parameters, i.e. $K$ and initial and final depletion, each of the 4 scenarios (for assumed shape and $r$) were fitted to a perfect index of abundance, based on the RAM estimates of biomass. This provides unbiased priors consistent with the assessment estimates, CVs were set to 30\%. This allows the Value-of-Infomation to be evaluated, i.e. how improving priors would increase yield. In addition heuristics for $K$, initial and final depletion was evaluated.


Table \ref{tab:grid} summarises the alternative stock assessment assumptions made when running JABBA as a catch only method (COM). 

We used Receiver Operating Characteristic curves to visualise the ability of models and reference points to identify whether a stock is overfished. To be useful for classification an indicator must have a high true positive rate (TPR) together with a low false-positive rate (FPR). A ROC curve, therefore, plots the TPR against the FPR. The area under the ROC curve gives an idea about the usefulness of a test, as the greater the area under a curve the better the test. The areas under ROC curves can also be used used to compare the usefulness of tests. ROC curves were first employed in the study of discriminator systems for the detection of radio signals in the presence of noise in the 1940s, following the attack on Pearl Harbor. The initial research was motivated by the desire to determine how the US RADAR "receiver operators" had missed the Japanese aircraft.
\end{itemize}

To be useful for classification an indicator must have a high true positive rate (TPR) together with a low false-positive rate (FPR). A ROC curve, therefore, plots the TPR against the FPR. The area under the ROC curve gives an idea about the usefulness of a test, as the greater the area under a curve the better the test. The areas under ROC curves can also be used used to compare the usefulness of tests. ROC curves were first employed in the study of discriminator systems for the detection of radio signals in the presence of noise in the 1940s, following the attack on Pearl Harbor. The initial research was motivated by the desire to determine how the US RADAR "receiver operators" had missed the Japanese aircraft.

A ROC curve plots the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings. %ROC curves can be thought of as a plot of the power as a function of the Type I Error of the decision rule. 
The ROC curves are constructed by sorting the observed values from the OM ($B/B_{MSY}$ and $F/F_{MSY}$) by their predicted scores based on the LBI with the highest scores first. The cumulative True Positive Rate (TPR) and True Negative Rate (TNR) are then calculated for the ordered observed outcomes. The ROC curve is then generated by plotting the cumulative distribution function (area under the probability distribution from to the discrimination threshold) of the detection probability in the y-axis versus the cumulative distribution function of the false-alarm probability on the x-axis. A ROC analysis, therefore, provides a tool to select the best candidate indicators. 

The best performing indicators should pass through the top lefthand corner, as only positive cases should be identified, i.e. TPR=1 \& FPR=0. Since the ROC is a probability curve the area under the curve (AUC) is an important metric for measuring performance. For example, a coin toss would produce a curve that fell along the $y=x$ line and the AUC would be equal to 0.5. The AUC, therefore, is a measure of how well an index is capable of distinguishing between states. The higher is the AUC, the better the model is at predicting. The ROC can also be used to identify the performance of a reference point, since the reference point is used as a discriminate threshold it should be the close point to TPR=1 \& FPR=0.

%Since risks are asymmetric, i.e. the risk of indicating overfishing is occurring when the stock is sustainably exploited is not the same as the risk of failing to identify overfishing, and so it may be desirable to adjust the threshold to increase or decrease the sensitivity to false positives.


